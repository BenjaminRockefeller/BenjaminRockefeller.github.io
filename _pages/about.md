---
layout: about
title: Start Here
permalink: /

profile:
  align: right
  image: ben.jpg
  image_circular: true
  image_style: "margin-top: -30px;"  # å¤´åƒä¸Šç§»ï¼Œé è¿‘å³ä¸Šè§’
  more_info: >
    <div style="margin-top: 1em; padding: 1em; background-color: #f8f9fa; border-radius: 10px; font-size: 16px; line-height: 1.6;">
      <p><strong>ğŸ“ MSc in Applied Economics</strong><br>Nanyang Technological University</p>
      <p><strong>ğŸ“ BA in International Economics and Trade</strong><br>Nankai University</p>
      <p><strong>ğŸ“¬</strong> <a href="mailto:jianming001@e.ntu.edu.sg">jianming001@e.ntu.edu.sg</a></p>
      <p><strong>ğŸ”—</strong> <a href="https://linkedin.com/in/benjaminrockefeller" target="_blank">LinkedIn</a></p>
    </div>

selected_papers: false
social: false
announcements:
  enabled: false
latest_posts:
  enabled: false
---
## ğŸ”· Research Interest

What does it take for AI to be truly trustworthy?  
Not just fluency, but cognitionâ€”with conscience.

Todayâ€™s LLMs generate fluent answersâ€”yet canâ€™t distinguish truth from fiction, explain their reasoning, or fix mistakes. This is not a bug, but a cognitive gap between language and thought.

My research bridges this gap by designing closed-loop generation systemsâ€”models that reflect, revise, and justify their outputs in real time, such as REFLEXION, which embeds structured feedback loops into Transformers to mitigate hallucinations, and CAT, a citation-aware tagging system that grounds outputs in verifiable sources.

These systems are not patches. Theyâ€™re prototypes of a new generation of cognitively aligned modelsâ€”capable not just of answering, but of thinking, explaining, and improving.

In the long term, I aim to move beyond sequential token prediction toward nonlinear, associative, and adaptive inferenceâ€”mirroring human cognition through structured internal dynamics, not imitation.

That means being precise enough to decide,  
grounded enough to be verified,  
and self-evolving enough to grow beyond its limits.

---

## ğŸ”· Technical Focus

What sets me apart is a rare blend of **deep LLM engineering expertise** and **real-world product leadership**.

With 6+ years of experience spanning product design, strategic execution, and enterprise deployment, I bridge the gap between frontier AI research and practical, scalable solutions.

While I may not be the strongest coder, Iâ€™m one of the few who can **consistently turn models into real-world impact**â€”grounded in business value, built for deployment, and designed to withstand real constraints.

- **Fine-tuning & Adaptation**: LoRA, QLoRA, multi-task learning, continual training  
- **Retrieval & Reasoning**: RAG, tool-calling, context-aware QA, long-document synthesis  
- **RL for Alignment**: PPO, DPO, RLAIF, reward modeling  
- **AI Agents**: LangGraph, AutoGen, orchestration, dynamic routing  
- **Memory Systems**: MCP (Model Context Protocol), persistent agent memory  
- **Inference Optimization**: vLLM, LMDeploy, INT8 quant, hybrid CPU-GPU scheduling  
- **System Engineering**: tokenizer design, version control, CI/CD, deployment pipelines  
- **Evaluation**: hallucination benchmarking, prompt stress tests, robustness auditing  

---

> I donâ€™t just build for performance. I build for **purpose**â€”and I deliver where it counts.
