---
layout: about
title: Start Here
permalink: /
subtitle: LLM Engineer | AI Researcher | Economics-Driven Systems Thinker from Nanyang Technological University

profile:
  align: right
  image: ben.jpg
  image_circular: true
  image_style: "margin-top: -30px;"  # å°†å¤´åƒæ•´ä½“ä¸Šç§»ï¼Œè´´è¿‘æ ‡é¢˜
  more_info: >
    <div style="margin-top: 1.2em; font-size: 17px; line-height: 1.6;">
      <p><strong>ðŸŽ“ MSc in Applied Economics</strong><br>Nanyang Technological University</p>
      <p><strong>ðŸŽ“ BA in International Economics and Trade</strong><br>Nankai University</p>
      <p><strong>ðŸ“¬</strong> <a href="mailto:jianming001@e.ntu.edu.sg">jianming001@e.ntu.edu.sg</a></p>
      <p><strong>ðŸ”—</strong> <a href="https://linkedin.com/in/benjaminrockefeller" target="_blank">LinkedIn</a></p>
    </div>

selected_papers: false
social: false
announcements:
  enabled: false
latest_posts:
  enabled: false
---

## ðŸ”· Research Interest
What does it take for AI to be truly trustworthy?
Not just fluency, but cognitionâ€”with conscience.
Todayâ€™s LLMs generate fluent answersâ€”yet canâ€™t distinguish truth from fiction, explain their reasoning, or fix mistakes. This is not a bug, but a cognitive gap between language and thought.
My research bridges this gap by designing closed-loop generation systemsâ€”models that reflect, revise, and justify their outputs in real time, such as REFLEXION, which embeds structured feedback loops into Transformers to mitigate hallucinations, and CAT, a citation-aware tagging system that grounds outputs in verifiable sources.
These systems are not patches.Theyâ€™re prototypes of a new generation of cognitively aligned modelsâ€”capable not just of answering, but of thinking, explaining, and improving.
In the long term, I aim to move beyond sequential token prediction toward nonlinear, associative, and adaptive inferenceâ€”mirroring human cognition through structured internal dynamics, not imitation.
That means being precise enough to decide,
grounded enough to be verified,
and self-evolving enough to grow beyond its limits.

---

## ðŸ”· Technical Focus

What sets me apart is a rare blend of deep LLM engineering expertise and real-world product leadership.

With over 6 years of experience spanning product design, strategic execution, cross-functional delivery, and digital transformation, I understand not only how to build large-scale AI systemsâ€”but why they matter, who they serve, and what it takes to make them operate reliably in high-stakes environments.

I may not be the strongest coderâ€”but Iâ€™m one of the few LLM engineers who can consistently translate abstract models into resilient, user-grounded, and business-aligned solutionsâ€”built for ambiguity, deployed under constraints, and designed for scale.

I donâ€™t just build for performance.  
I build for purposeâ€”and I deliver where it counts.

- Fine-tuning & Adaptation: LoRA, QLoRA, multi-task learning, continual training  
- Retrieval & Reasoning: RAG, tool-calling, context-aware QA, long-document reasoning  
- Reinforcement Learning: PPO, DPO, RLAIF, reward modeling, alignment tuning  
- AI Agents: LangGraph, AutoGen, agent orchestration, task routing, feedback loops  
- Memory & State (MCP): Model Context Protocol design for long-range multi-agent memory  
- Inference Optimization: vLLM, LMDeploy, INT8 quantization, GPU/CPU hybrid scheduling  
- System Engineering: tokenizer design, model versioning, CI/CD pipelines, deployment infra  
- Robustness & Evaluation: prompt stress tests, hallucination benchmarks, intent-grounded metrics  

---
