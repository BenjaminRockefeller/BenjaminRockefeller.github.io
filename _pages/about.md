---
layout: about
title: Start Here
permalink: /
subtitle: LLM Engineer | AI Researcher | Economics-Driven Systems Thinker from Nanyang Technological University

profile:
  align: right
  image: ben.jpg
  image_circular: true
  image_style: "margin-top: -30px;"  # 将头像整体上移，贴近标题
  more_info: >
    <div style="margin-top: 1.2em; font-size: 17px; line-height: 1.6;">
      <p><strong>🎓 MSc in Applied Economics</strong><br>Nanyang Technological University</p>
      <p><strong>🎓 BA in International Economics and Trade</strong><br>Nankai University</p>
      <p><strong>📬</strong> <a href="mailto:jianming001@e.ntu.edu.sg">jianming001@e.ntu.edu.sg</a></p>
      <p><strong>🔗</strong> <a href="https://linkedin.com/in/benjaminrockefeller" target="_blank">LinkedIn</a></p>
    </div>

selected_papers: false
social: false
announcements:
  enabled: false
latest_posts:
  enabled: false
---

## 🔷 Research Interest
What does it take for AI to be truly trustworthy?
Not just fluency, but cognition—with conscience.
Today’s LLMs generate fluent answers—yet can’t distinguish truth from fiction, explain their reasoning, or fix mistakes. This is not a bug, but a cognitive gap between language and thought.
My research bridges this gap by designing closed-loop generation systems—models that reflect, revise, and justify their outputs in real time, such as REFLEXION, which embeds structured feedback loops into Transformers to mitigate hallucinations, and CAT, a citation-aware tagging system that grounds outputs in verifiable sources.
These systems are not patches.They’re prototypes of a new generation of cognitively aligned models—capable not just of answering, but of thinking, explaining, and improving.
In the long term, I aim to move beyond sequential token prediction toward nonlinear, associative, and adaptive inference—mirroring human cognition through structured internal dynamics, not imitation.
That means being precise enough to decide,
grounded enough to be verified,
and self-evolving enough to grow beyond its limits.

---

## 🔷 Technical Focus

What sets me apart is a rare blend of deep LLM engineering expertise and real-world product leadership.

With over 6 years of experience spanning product design, strategic execution, cross-functional delivery, and digital transformation, I understand not only how to build large-scale AI systems—but why they matter, who they serve, and what it takes to make them operate reliably in high-stakes environments.

I may not be the strongest coder—but I’m one of the few LLM engineers who can consistently translate abstract models into resilient, user-grounded, and business-aligned solutions—built for ambiguity, deployed under constraints, and designed for scale.

I don’t just build for performance.  
I build for purpose—and I deliver where it counts.

- Fine-tuning & Adaptation: LoRA, QLoRA, multi-task learning, continual training  
- Retrieval & Reasoning: RAG, tool-calling, context-aware QA, long-document reasoning  
- Reinforcement Learning: PPO, DPO, RLAIF, reward modeling, alignment tuning  
- AI Agents: LangGraph, AutoGen, agent orchestration, task routing, feedback loops  
- Memory & State (MCP): Model Context Protocol design for long-range multi-agent memory  
- Inference Optimization: vLLM, LMDeploy, INT8 quantization, GPU/CPU hybrid scheduling  
- System Engineering: tokenizer design, model versioning, CI/CD pipelines, deployment infra  
- Robustness & Evaluation: prompt stress tests, hallucination benchmarks, intent-grounded metrics  

---
