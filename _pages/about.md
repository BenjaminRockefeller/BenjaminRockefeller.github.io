---
layout: about
title: Start Here
permalink: /

profile:
  align: right
  image: ben.jpg
  image_circular: true
  image_style: "margin-top: -30px;"  # 头像上移，靠近右上角
  more_info: >
    <div style="margin-top: 1em; padding: 1em; background-color: #f8f9fa; border-radius: 10px; font-size: 16px; line-height: 1.6;">
      <p><strong>🎓 MSc in Applied Economics</strong><br>Nanyang Technological University</p>
      <p><strong>🎓 BA in International Economics and Trade</strong><br>Nankai University</p>
      <p><strong>📬</strong> <a href="mailto:jianming001@e.ntu.edu.sg">jianming001@e.ntu.edu.sg</a></p>
      <p><strong>🔗</strong> <a href="https://linkedin.com/in/benjaminrockefeller" target="_blank">LinkedIn</a></p>
    </div>

selected_papers: false
social: false
announcements:
  enabled: false
latest_posts:
  enabled: false
---
## 🔷 Research Interest

What does it take for AI to be truly trustworthy?  
Not just fluency, but cognition—with conscience.

Today’s LLMs generate fluent answers—yet can’t distinguish truth from fiction, explain their reasoning, or fix mistakes. This is not a bug, but a cognitive gap between language and thought.

My research bridges this gap by designing closed-loop generation systems—models that reflect, revise, and justify their outputs in real time, such as REFLEXION, which embeds structured feedback loops into Transformers to mitigate hallucinations, and CAT, a citation-aware tagging system that grounds outputs in verifiable sources.

These systems are not patches. They’re prototypes of a new generation of cognitively aligned models—capable not just of answering, but of thinking, explaining, and improving.

In the long term, I aim to move beyond sequential token prediction toward nonlinear, associative, and adaptive inference—mirroring human cognition through structured internal dynamics, not imitation.

That means being precise enough to decide,  
grounded enough to be verified,  
and self-evolving enough to grow beyond its limits.

---

## 🔷 Technical Focus

What sets me apart is a rare blend of **deep LLM engineering expertise** and **real-world product leadership**.

With 6+ years of experience spanning product design, strategic execution, and enterprise deployment, I bridge the gap between frontier AI research and practical, scalable solutions.

While I may not be the strongest coder, I’m one of the few who can **consistently turn models into real-world impact**—grounded in business value, built for deployment, and designed to withstand real constraints.

- **Fine-tuning & Adaptation**: LoRA, QLoRA, multi-task learning, continual training  
- **Retrieval & Reasoning**: RAG, tool-calling, context-aware QA, long-document synthesis  
- **RL for Alignment**: PPO, DPO, RLAIF, reward modeling  
- **AI Agents**: LangGraph, AutoGen, orchestration, dynamic routing  
- **Memory Systems**: MCP (Model Context Protocol), persistent agent memory  
- **Inference Optimization**: vLLM, LMDeploy, INT8 quant, hybrid CPU-GPU scheduling  
- **System Engineering**: tokenizer design, version control, CI/CD, deployment pipelines  
- **Evaluation**: hallucination benchmarking, prompt stress tests, robustness auditing  

---

> I don’t just build for performance. I build for **purpose**—and I deliver where it counts.
