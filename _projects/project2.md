---
layout: page
title: "Project 2ï½œIntelligent Quantitative Strategy Generation Platform"
permalink: /projects/project2/
importance: 2
category: work
---

<style>
  /* --- local style overrides to make the page more readable & visually striking --- */
  h1.project-title {
    font-size: 32px;
    font-weight: 800;
    margin-bottom: 0.6em;
  }
  h2.project-subtitle {
    font-size: 24px;
    font-weight: 700;
    margin-top: 0.8em;
    margin-bottom: 0.5em;
  }
  h3 {
    font-size: 21px;
    font-weight: 600;
    margin-top: 0.9em;
    margin-bottom: 0.4em;
  }
  p, li {
    font-size: 17px;
    line-height: 1.7em;
  }
  table {
    font-size: 16px;
  }
  .highlight {
    color: #1a73e8;
    font-weight: 700;
  }
</style>

# <span class="project-title">ðŸ“ˆ Project 2ï½œIntelligent Quantitative Strategy Generation Platform</span>

## <span class="project-subtitle">Causalityâ€‘Aware RLHF Optimization with Backtest Feedback Loop</span>

### 1. Project Overview

This platform solves longâ€‘standing issues in quant strategy developmentâ€”**unverifiable outputs, missing causal structure, and high deployment cost**â€”by integrating strategy generation, causal graph refinement, RLHF optimization, and backâ€‘test feedback into a single closed loop.

### 2. Key Contributions

- **Rich Multiâ€‘Source Dataset**Â (>Â 800â€¯K items)
  - 12â€¯K strategy abstracts, 11â€¯K indicator chains, 9â€¯K causal market graphs
  - Sources: privateâ€‘fund docs, causal event DBs, Tushare logs
- **Causal Graph Alignment**Â â†’ structural consistency â†‘Â fromÂ 71.2â€¯%Â toÂ 94.6â€¯%
  - spaCy + regex tree extraction; custom GraphDB entity merge; 5â€‘round human QA
- **Multiâ€‘Task Distillation**Â with **LLaMAâ€‘2â€‘7B teacher**
  - Softâ€‘label (TÂ =Â 2.0), structureâ€‘aware prompts, loss weightsÂ 0.4Â /Â 0.4Â /Â 0.2
- **Custom RLHF Reward (3â€‘Dimensional)**
  1. CausalÂ CoverageÂ Â Â 2. CoherenceÂ ScoreÂ Â Â 3. Backâ€‘test ReturnÂ &Â Stability
  - Uses reward clipping + early baseline â†’ avoids collapse
- **Backâ€‘test Feedback Loop**
  - Autogenerates Backtrader scripts â†’ collects Sharpe/return/drawdown
  - Feeds metrics back into PPO; enables *generate â†’ simulate â†’ retrain* cycle
- **Deployment Optimisation**
  - QLoRAÂ (rankÂ =Â 8)Â +Â TensorRTÂ INT4 â‡’Â modelÂ â†“Â 65Â %; latencyÂ 270â€¯ms;Â 26Â req/s on RTXÂ 3090

### 3. Experimental Results

| Metric | Improvement |
|--------|-------------|
| BLEU | **+14.6â€¯%** |
| Redundancy | **â€‘21.2â€¯%** |
| CausalÂ MatchingÂ Acc. | **85.4â€¯%** |
| Strategy SimulationÂ Success | **78.9â€¯%** |
| Avg. Human Rating | **4.7Â /Â 5.0** |
| Convergence Speed | **+32â€¯%** (RLHFÂ +Â backâ€‘test reward) |

### 4. Future Roadmap

- **Ablation Studies**Â (noâ€‘causal / noâ€‘reward / genericâ€‘RLHF)
- **Interactive Visualisation**Â (D3Â +Â Plotly for causal graphs & ROI curves)
- **Crossâ€‘Model Portability**Â (InternLM, Mistralâ€‘7B, Yiâ€‘6B,Â <Â 2.7â€¯% error)
- **Advanced RL Fusion**Â (Qâ€‘learningÂ /Â R2D2 autoâ€‘rewrite when ROIÂ â†“)

### 5. TechÂ Stack

LLaMAâ€‘2â€‘7B Â· QLoRA Â· Custom RLHF Â· Softâ€‘Label Distillation Â· Backtrader Â· GraphDB Â· spaCy Â· PromptÂ Chain Â· PyTorchÂ Lightning Â· FastAPI Â· TensorRTÂ INT4 Â· Docker Â· WandB Â· RTXÂ 3090
